{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import TypedDict, List, Dict, Optional\n",
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "\n",
    "# LLM and embedding related imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Evaluation related imports\n",
    "from ragas.metrics import AnswerAccuracy, ContextRelevance, ResponseGroundedness\n",
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Vector Store Setup\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vectorstore = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 documents from Anthropic Wikipedia.pdf\n",
      "Loaded 11 documents from Mistral AI.pdf\n",
      "Loaded 7 documents from XAI PDF Wikipedia.pdf\n",
      "Loaded 40 documents from Nvidia PDF Wikipedia.pdf\n",
      "Loaded 55 documents from OpenAI Wikipedia.pdf\n",
      "Loaded 19 documents from DeepSeek Wikipedia.pdf\n",
      "Loaded 5 documents from Hugging Face.pdf\n",
      "Loaded 24 documents from DeepMind Wikipedia.pdf\n",
      "Total documents loaded: 170\n"
     ]
    }
   ],
   "source": [
    "# Document Loading\n",
    "\n",
    "docs = []\n",
    "data_folder = \"data\"\n",
    "\n",
    "if os.path.exists(data_folder) and os.path.isdir(data_folder):\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                file_docs = loader.load()\n",
    "                docs.extend(file_docs)\n",
    "                print(f\"Loaded {len(file_docs)} documents from {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "else:\n",
    "    print(f\"Folder {data_folder} does not exist or is not a directory\")\n",
    "\n",
    "print(f\"Total documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents into chunks...\n",
      "Splitted documents into: 729 chunks\n",
      "Adding documents to vector store...\n",
      "Documents added to vector store\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Document Processing and Vectorization\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "print(\"Splitting documents into chunks...\")\n",
    "splitted_docs = text_splitter.split_documents(docs)\n",
    "print(f\"Splitted documents into: {len(splitted_docs)} chunks\")\n",
    "\n",
    "print(\"Adding documents to vector store...\")\n",
    "_ = vectorstore.add_documents(splitted_docs)\n",
    "print(\"Documents added to vector store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RAG pipeline ready\n"
     ]
    }
   ],
   "source": [
    "# RAG Pipeline Implementation with LangGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    \n",
    "def retrieve(state: State):\n",
    "    print(f\"üîç Retrieving documents for: {state['query']}\")\n",
    "    retriever = vectorstore.similarity_search(query=state[\"query\"], k=2)\n",
    "    return {\"context\": retriever}\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    print(\"üí¨ Generating answer...\")\n",
    "    \n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful AI assistant. Answer the question based only on the context provided. \n",
    "    If the context doesn't contain the information needed to answer the question, say \"I don't have enough information to answer this question.\"\n",
    "    \n",
    "    Question: {state[\"query\"]}\n",
    "    Context: {docs_content}\n",
    "    \n",
    "    Provide a concise and accurate answer based solely on the information in the context:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Build RAG pipeline graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Connect nodes in sequence\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate_answer\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "print(\"‚úì RAG pipeline ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieving documents for: what is deep mind?\n",
      "üí¨ Generating answer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is deep mind?',\n",
       " 'context': [Document(id='af0222c0-63be-4f11-87e3-9d0e2ae90819', metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-05-11T18:49:21+00:00', 'title': 'Google DeepMind - Wikipedia', 'moddate': '2025-05-11T18:49:21+00:00', 'source': 'data/DeepMind Wikipedia.pdf', 'total_pages': 24, 'page': 0, 'page_label': '1'}, page_content=\"laboratory which serves as a subsidiary of Alphabet\\nInc. Founded in the UK in 2010, it was acquired by\\nGoogle in 2014[8] and merged with Google AI's\\nGoogle Brain division to become Google DeepMind\\nin April 2023. The company is headquartered in\\nLondon, with research centres in the United States,\\nCanada,[9] France,[10] Germany and Switzerland.\\nDeepMind introduced neural Turing machines (neural\\nnetworks that can access external memory like a\\nconventional Turing machine),[11] resulting in a\\ncomputer that loosely resembles short-term memory\\nin the human brain.[12][13]\\nDeepMind has created neural network models to play\\nvideo games and board games. It made headlines in\\n2016 after its AlphaGo program beat a human\\nprofessional Go player Lee Sedol, a world champion,\\nin a five-game match, which was the subject of a\\ndocumentary film.[14] A more general program,\\nAlphaZero, beat the most powerful programs playing\\ngo, chess and shogi (Japanese chess) after a few days\"),\n",
       "  Document(id='24059ba5-fa5b-4011-ae87-6b80471f2b6c', metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/135.0.0.0 Safari/537.36', 'creationdate': '2025-05-11T18:49:21+00:00', 'title': 'Google DeepMind - Wikipedia', 'moddate': '2025-05-11T18:49:21+00:00', 'source': 'data/DeepMind Wikipedia.pdf', 'total_pages': 24, 'page': 0, 'page_label': '1'}, page_content=\"DeepMind Technologies Limited\\nTrade name Google DeepMind\\nDeepMind\\nCompany type Subsidiary\\nIndustry Artificial intelligence\\nFounded 23 September 2010\\n(incorporation)[1]\\n15 November 2010 (official\\nlaunch)[2]\\nFounders Demis Hassabis\\nShane Legg\\nMustafa Suleyman\\nHeadquarters London, England[3]\\nKey people Demis Hassabis (CEO)\\nLila Ibrahim (COO)\\nProducts AlphaGo\\nAlphaStar\\nAlphaFold\\nAlphaZero\\nRevenue\\n  ¬£1.53 billion (2023)[4]\\nOperating\\nincome\\n ¬£136 million (2023)[4]\\nNet income\\n  ¬£113 million (2023)[4]\\nOwner Alphabet Inc.[5]\\nNumber of\\nemployees\\nc. 2,600 (2024)[6]\\nParent Deepmind Holdings\\nLimited[7]\\nWebsite deepmind.google (https://de\\nepmind.google/)\\nGoogle DeepMind\\nDeepMind Technologies Limited,[1] trading as\\nGoogle DeepMind or simply DeepMind, is a\\nBritish‚ÄìAmerican artificial intelligence research\\nlaboratory which serves as a subsidiary of Alphabet\\nInc. Founded in the UK in 2010, it was acquired by\\nGoogle in 2014[8] and merged with Google AI's\\nGoogle Brain division to become Google DeepMind\")],\n",
       " 'answer': 'DeepMind, officially known as Google DeepMind, is a British-American artificial intelligence research laboratory and a subsidiary of Alphabet Inc. Founded in 2010, it focuses on developing advanced AI technologies, including neural networks and programs like AlphaGo and AlphaZero.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"query\": \"what is deep mind?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset...\n",
      "Loaded 42 test examples with query - ground_truth pairs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was OpenAI founded?</td>\n",
       "      <td>December 8, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who are the founders of OpenAI?</td>\n",
       "      <td>John Schulman, Elon Musk, Ilya Sutskever, Sam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is OpenAI's mission?</td>\n",
       "      <td>To ensure that AGI benefits all of humanity.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query  \\\n",
       "0         When was OpenAI founded?   \n",
       "1  Who are the founders of OpenAI?   \n",
       "2        What is OpenAI's mission?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0                                   December 8, 2015  \n",
       "1  John Schulman, Elon Musk, Ilya Sutskever, Sam ...  \n",
       "2       To ensure that AGI benefits all of humanity.  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: Load and Explore Test Dataset\n",
    "print(\"Loading test dataset...\")\n",
    "test_data = pd.read_csv(\"test-set/synthetic-test-set.csv\")\n",
    "print(f\"Loaded {len(test_data)} test examples with query - ground_truth pairs\")\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 42 test questions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af532fd91fa4195a5258181898875ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieving documents for: When was OpenAI founded?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who are the founders of OpenAI?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is OpenAI's mission?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What are some key products developed by OpenAI?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is OpenAI headquartered?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who is OpenAI's current CEO?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Which major company invested $13 billion in OpenAI?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is the estimated revenue of OpenAI in 2024?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Why did Elon Musk leave OpenAI?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is the name of OpenAI‚Äôs AI chatbot released in November 2022?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: When was Anthropic founded?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who founded Anthropic?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is the name of Anthropic's language model?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Which companies invested billions in Anthropic?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is Anthropic headquartered?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is Anthropic's public-benefit structure called?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: When was DeepMind founded?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who founded DeepMind?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Which company acquired DeepMind?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What are some of DeepMind's notable products?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is DeepMind headquartered?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: When was Mistral AI founded?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who founded Mistral AI?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is Mistral AI known for?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Which major partnership did Mistral AI announce in 2024?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is Mistral AI based?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: When was Hugging Face founded?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who are the founders of Hugging Face?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is Hugging Face headquartered?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is Hugging Face most known for?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is BLOOM?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What did Hugging Face acquire in 2022?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who founded Nvidia?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is Nvidia headquartered?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is CUDA?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Which Nvidia product is aimed at the consumer market?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is Nvidia's fiscal year 2025 revenue?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Where is DeepSeek based?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: Who founded DeepSeek?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What model did DeepSeek launch in January 2025?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What is unique about DeepSeek‚Äôs model training?\n",
      "üí¨ Generating answer...\n",
      "üîç Retrieving documents for: What licensing does DeepSeek-R1 use?\n",
      "üí¨ Generating answer...\n",
      "‚úì Successfully generated answers for 42 questions\n",
      "Results saved to 'test_results.json'\n"
     ]
    }
   ],
   "source": [
    "# Processing of Test Questions\n",
    "\n",
    "print(f\"Processing {len(test_data)} test questions...\")\n",
    "results = []\n",
    "\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Generating answers\"):\n",
    "    query = row['query']\n",
    "    ground_truth = row['ground_truth']\n",
    "    \n",
    "    result = graph.invoke({\"query\": query})\n",
    "    \n",
    "    results.append({\n",
    "        \"query\": query,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"response\": result[\"answer\"],\n",
    "        \"contexts\": [doc.page_content for doc in result[\"context\"]]\n",
    "    })\n",
    "    \n",
    "   \n",
    "\n",
    "# Save final results to JSON file\n",
    "with open(\"test_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Successfully generated answers for {len(results)} questions\")\n",
    "print(f\"Results saved to 'test_results.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing evaluation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42094bd09124755a15c0039b2c931a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting to RAGAS format:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prepared evaluation dataset with 42 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare Evaluation Dataset for RAGAS\n",
    "print(\"Preparing evaluation dataset...\")\n",
    "samples = []\n",
    "\n",
    "# Convert results to RAGAS format\n",
    "for item in tqdm(results, desc=\"Converting to RAGAS format\"):\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=item[\"query\"],\n",
    "        response=item[\"response\"],\n",
    "        reference=item[\"ground_truth\"],\n",
    "        retrieved_contexts=item[\"contexts\"]\n",
    "    )\n",
    "    samples.append(sample)\n",
    "\n",
    "# Create evaluation dataset\n",
    "dataset = EvaluationDataset(samples=samples)\n",
    "print(f\"‚úì Prepared evaluation dataset with {len(samples)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAGAS evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d57710ed0e4dec8b90808d850718fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Evaluation complete\n",
      "{'nv_accuracy': 0.7321, 'nv_context_relevance': 0.9286, 'nv_response_groundedness': 0.9524}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>nv_accuracy</th>\n",
       "      <th>nv_context_relevance</th>\n",
       "      <th>nv_response_groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was OpenAI founded?</td>\n",
       "      <td>[OpenAI\\nCompany type Private\\nIndustry Artifi...</td>\n",
       "      <td>OpenAI was founded on December 8, 2015.</td>\n",
       "      <td>December 8, 2015</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who are the founders of OpenAI?</td>\n",
       "      <td>[Website openai.com (https://openai.\\ncom/)\\nF...</td>\n",
       "      <td>The founders of OpenAI are Sam Altman, Elon Mu...</td>\n",
       "      <td>John Schulman, Elon Musk, Ilya Sutskever, Sam ...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is OpenAI's mission?</td>\n",
       "      <td>[to develop \"safe and beneficial\" artificial g...</td>\n",
       "      <td>OpenAI's mission is to develop \"safe and benef...</td>\n",
       "      <td>To ensure that AGI benefits all of humanity.</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some key products developed by OpenAI?</td>\n",
       "      <td>[to develop \"safe and beneficial\" artificial g...</td>\n",
       "      <td>Some key products developed by OpenAI include ...</td>\n",
       "      <td>ChatGPT, GPT models, DALL¬∑E, Codex, Sora</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where is OpenAI headquartered?</td>\n",
       "      <td>[OpenAI\\nCompany type Private\\nIndustry Artifi...</td>\n",
       "      <td>OpenAI is headquartered at 1455 3rd Street, Sa...</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who is OpenAI's current CEO?</td>\n",
       "      <td>[private technology deal on record. The financ...</td>\n",
       "      <td>OpenAI's current CEO is Sam Altman.</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Which major company invested $13 billion in Op...</td>\n",
       "      <td>[In December 2022, OpenAI received widespread ...</td>\n",
       "      <td>Microsoft invested $10 billion in OpenAI.</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the estimated revenue of OpenAI in 2024?</td>\n",
       "      <td>[In December 2022, OpenAI received widespread ...</td>\n",
       "      <td>The estimated revenue of OpenAI in 2024 is $1 ...</td>\n",
       "      <td>$3.7 billion</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why did Elon Musk leave OpenAI?</td>\n",
       "      <td>[32. Claburn, Thomas. \"Elon Musk-backed OpenAI...</td>\n",
       "      <td>Elon Musk left the board of an AI safety group...</td>\n",
       "      <td>Due to a potential future conflict of interest...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the name of OpenAI‚Äôs AI chatbot releas...</td>\n",
       "      <td>[The release of ChatGPT was a major\\nevent in ...</td>\n",
       "      <td>The name of OpenAI‚Äôs AI chatbot released in No...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When was Anthropic founded?</td>\n",
       "      <td>[increasingly powerful AI systems.[16]\\nIn Feb...</td>\n",
       "      <td>I don't have enough information to answer this...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Who founded Anthropic?</td>\n",
       "      <td>[Anthropic PBC\\nLogo\\nCompany type Private\\nIn...</td>\n",
       "      <td>Anthropic was founded by Dario Amodei, Daniela...</td>\n",
       "      <td>Dario Amodei, Daniela Amodei, Jared Kaplan, Ja...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the name of Anthropic's language model?</td>\n",
       "      <td>[Anthropic PBC\\nLogo\\nCompany type Private\\nIn...</td>\n",
       "      <td>The name of Anthropic's language model is Claude.</td>\n",
       "      <td>Claude</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Which companies invested billions in Anthropic?</td>\n",
       "      <td>[Anthropic's corporate structure\\ninvestment o...</td>\n",
       "      <td>The companies that invested billions in Anthro...</td>\n",
       "      <td>Amazon and Google</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Where is Anthropic headquartered?</td>\n",
       "      <td>[awsuit-2024-01-17/). Reuters. Retrieved 2024-...</td>\n",
       "      <td>Anthropic is headquartered in San Francisco, C...</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is Anthropic's public-benefit structure c...</td>\n",
       "      <td>[In 2024, Anthropic attracted several notable ...</td>\n",
       "      <td>Anthropic's public-benefit structure is called...</td>\n",
       "      <td>Delaware public-benefit corporation</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>When was DeepMind founded?</td>\n",
       "      <td>[DeepMind Technologies Limited\\nTrade name Goo...</td>\n",
       "      <td>DeepMind was founded on 23 September 2010.</td>\n",
       "      <td>September 23, 2010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Who founded DeepMind?</td>\n",
       "      <td>[understand and attempt to master it.\"[20] The...</td>\n",
       "      <td>DeepMind was founded by Demis Hassabis, Shane ...</td>\n",
       "      <td>Demis Hassabis, Shane Legg, Mustafa Suleyman</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Which company acquired DeepMind?</td>\n",
       "      <td>[DeepMind Technologies Limited\\nTrade name Goo...</td>\n",
       "      <td>Google acquired DeepMind in 2014.</td>\n",
       "      <td>Google</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What are some of DeepMind's notable products?</td>\n",
       "      <td>[laboratory which serves as a subsidiary of Al...</td>\n",
       "      <td>Some of DeepMind's notable products include Al...</td>\n",
       "      <td>AlphaGo, AlphaStar, AlphaFold, AlphaZero</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Where is DeepMind headquartered?</td>\n",
       "      <td>[DeepMind Technologies Limited\\nTrade name Goo...</td>\n",
       "      <td>DeepMind is headquartered in London, England.</td>\n",
       "      <td>London, England</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>When was Mistral AI founded?</td>\n",
       "      <td>[Mistral AI SAS\\nCurrent logo since 2025\\nComp...</td>\n",
       "      <td>Mistral AI was founded on 28 April 2023.</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Who founded Mistral AI?</td>\n",
       "      <td>[Mistral AI\\nMistral AI SAS is a French artifi...</td>\n",
       "      <td>Mistral AI was founded by Arthur Mensch, Guill...</td>\n",
       "      <td>Arthur Mensch, Guillaume Lample, Timoth√©e Lacroix</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is Mistral AI known for?</td>\n",
       "      <td>[Mistral AI\\nMistral AI SAS is a French artifi...</td>\n",
       "      <td>Mistral AI is known for specializing in open-w...</td>\n",
       "      <td>Open-weight large language models</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Which major partnership did Mistral AI announc...</td>\n",
       "      <td>[es/tripling-down-on-mistral-ai). www.generalc...</td>\n",
       "      <td>Mistral AI announced a partnership with Micros...</td>\n",
       "      <td>Partnership with Microsoft</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Where is Mistral AI based?</td>\n",
       "      <td>[Mistral AI\\nMistral AI SAS is a French artifi...</td>\n",
       "      <td>Mistral AI is based in Paris, France.</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>When was Hugging Face founded?</td>\n",
       "      <td>[Hugging Face, Inc.\\nCompany type Private\\nInd...</td>\n",
       "      <td>Hugging Face was founded in 2016.</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Who are the founders of Hugging Face?</td>\n",
       "      <td>[Hugging Face, Inc.\\nCompany type Private\\nInd...</td>\n",
       "      <td>The founders of Hugging Face are Cl√©ment Delan...</td>\n",
       "      <td>Cl√©ment Delangue, Julien Chaumond, Thomas Wolf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Where is Hugging Face headquartered?</td>\n",
       "      <td>[Hugging Face, Inc.\\nCompany type Private\\nInd...</td>\n",
       "      <td>Hugging Face is headquartered in Manhattan, Ne...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What is Hugging Face most known for?</td>\n",
       "      <td>[Hugging Face, Inc.\\nCompany type Private\\nInd...</td>\n",
       "      <td>Hugging Face is most known for its transformer...</td>\n",
       "      <td>Transformers library for NLP</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What is BLOOM?</td>\n",
       "      <td>[OpenAI's \"Blossom\" is\\nused as a symbol for\\n...</td>\n",
       "      <td>I don't have enough information to answer this...</td>\n",
       "      <td>A multilingual large language model with 176 b...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What did Hugging Face acquire in 2022?</td>\n",
       "      <td>[In August 2023, the company announced that it...</td>\n",
       "      <td>In 2022, Hugging Face acquired Gradio, an open...</td>\n",
       "      <td>Gradio</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Who founded Nvidia?</td>\n",
       "      <td>[September 2020 failed to materialize followin...</td>\n",
       "      <td>Nvidia was founded by Jensen Huang, Chris Mala...</td>\n",
       "      <td>Jensen Huang, Chris Malachowsky, Curtis Priem</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Where is Nvidia headquartered?</td>\n",
       "      <td>[Nvidia Corporation\\nLogo used since 2006\\nHea...</td>\n",
       "      <td>Nvidia is headquartered in Santa Clara, Califo...</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is CUDA?</td>\n",
       "      <td>[On May 12, 2022, Nvidia announced that they a...</td>\n",
       "      <td>CUDA is Nvidia's software platform and API tha...</td>\n",
       "      <td>A platform and API for parallel computing usin...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Which Nvidia product is aimed at the consumer ...</td>\n",
       "      <td>[applications such as video editing, 3D render...</td>\n",
       "      <td>The Nvidia product aimed at the consumer marke...</td>\n",
       "      <td>GeForce</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What is Nvidia's fiscal year 2025 revenue?</td>\n",
       "      <td>[10-year financials (2016‚Äì2025)\\nYear Revenue\\...</td>\n",
       "      <td>Nvidia's fiscal year 2025 revenue is $130,497 ...</td>\n",
       "      <td>$130.57 billion</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Where is DeepSeek based?</td>\n",
       "      <td>[DeepSeek is headquartered in Hangzhou, Zhejia...</td>\n",
       "      <td>DeepSeek is based in Hangzhou, Zhejiang.</td>\n",
       "      <td>Hangzhou, Zhejiang, China</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Who founded DeepSeek?</td>\n",
       "      <td>[DeepSeek is headquartered in Hangzhou, Zhejia...</td>\n",
       "      <td>DeepSeek was co-founded by Liang Wenfeng.</td>\n",
       "      <td>Liang Wenfeng</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What model did DeepSeek launch in January 2025?</td>\n",
       "      <td>[The DeepSeek login page following a\\ncyberatt...</td>\n",
       "      <td>DeepSeek launched the DeepSeek chatbot based o...</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What is unique about DeepSeek‚Äôs model training?</td>\n",
       "      <td>[DeepSeek's models are described as \"open weig...</td>\n",
       "      <td>DeepSeek's model training is unique because it...</td>\n",
       "      <td>Low cost and efficiency using MoE layers</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>What licensing does DeepSeek-R1 use?</td>\n",
       "      <td>[real-time problem-solving. DeepSeek claimed t...</td>\n",
       "      <td>DeepSeek-R1 uses \"open weight\" licensing, mean...</td>\n",
       "      <td>MIT License</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0                            When was OpenAI founded?   \n",
       "1                     Who are the founders of OpenAI?   \n",
       "2                           What is OpenAI's mission?   \n",
       "3     What are some key products developed by OpenAI?   \n",
       "4                      Where is OpenAI headquartered?   \n",
       "5                        Who is OpenAI's current CEO?   \n",
       "6   Which major company invested $13 billion in Op...   \n",
       "7    What is the estimated revenue of OpenAI in 2024?   \n",
       "8                     Why did Elon Musk leave OpenAI?   \n",
       "9   What is the name of OpenAI‚Äôs AI chatbot releas...   \n",
       "10                        When was Anthropic founded?   \n",
       "11                             Who founded Anthropic?   \n",
       "12    What is the name of Anthropic's language model?   \n",
       "13    Which companies invested billions in Anthropic?   \n",
       "14                  Where is Anthropic headquartered?   \n",
       "15  What is Anthropic's public-benefit structure c...   \n",
       "16                         When was DeepMind founded?   \n",
       "17                              Who founded DeepMind?   \n",
       "18                   Which company acquired DeepMind?   \n",
       "19      What are some of DeepMind's notable products?   \n",
       "20                   Where is DeepMind headquartered?   \n",
       "21                       When was Mistral AI founded?   \n",
       "22                            Who founded Mistral AI?   \n",
       "23                      What is Mistral AI known for?   \n",
       "24  Which major partnership did Mistral AI announc...   \n",
       "25                         Where is Mistral AI based?   \n",
       "26                     When was Hugging Face founded?   \n",
       "27              Who are the founders of Hugging Face?   \n",
       "28               Where is Hugging Face headquartered?   \n",
       "29               What is Hugging Face most known for?   \n",
       "30                                     What is BLOOM?   \n",
       "31             What did Hugging Face acquire in 2022?   \n",
       "32                                Who founded Nvidia?   \n",
       "33                     Where is Nvidia headquartered?   \n",
       "34                                      What is CUDA?   \n",
       "35  Which Nvidia product is aimed at the consumer ...   \n",
       "36         What is Nvidia's fiscal year 2025 revenue?   \n",
       "37                           Where is DeepSeek based?   \n",
       "38                              Who founded DeepSeek?   \n",
       "39    What model did DeepSeek launch in January 2025?   \n",
       "40    What is unique about DeepSeek‚Äôs model training?   \n",
       "41               What licensing does DeepSeek-R1 use?   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [OpenAI\\nCompany type Private\\nIndustry Artifi...   \n",
       "1   [Website openai.com (https://openai.\\ncom/)\\nF...   \n",
       "2   [to develop \"safe and beneficial\" artificial g...   \n",
       "3   [to develop \"safe and beneficial\" artificial g...   \n",
       "4   [OpenAI\\nCompany type Private\\nIndustry Artifi...   \n",
       "5   [private technology deal on record. The financ...   \n",
       "6   [In December 2022, OpenAI received widespread ...   \n",
       "7   [In December 2022, OpenAI received widespread ...   \n",
       "8   [32. Claburn, Thomas. \"Elon Musk-backed OpenAI...   \n",
       "9   [The release of ChatGPT was a major\\nevent in ...   \n",
       "10  [increasingly powerful AI systems.[16]\\nIn Feb...   \n",
       "11  [Anthropic PBC\\nLogo\\nCompany type Private\\nIn...   \n",
       "12  [Anthropic PBC\\nLogo\\nCompany type Private\\nIn...   \n",
       "13  [Anthropic's corporate structure\\ninvestment o...   \n",
       "14  [awsuit-2024-01-17/). Reuters. Retrieved 2024-...   \n",
       "15  [In 2024, Anthropic attracted several notable ...   \n",
       "16  [DeepMind Technologies Limited\\nTrade name Goo...   \n",
       "17  [understand and attempt to master it.\"[20] The...   \n",
       "18  [DeepMind Technologies Limited\\nTrade name Goo...   \n",
       "19  [laboratory which serves as a subsidiary of Al...   \n",
       "20  [DeepMind Technologies Limited\\nTrade name Goo...   \n",
       "21  [Mistral AI SAS\\nCurrent logo since 2025\\nComp...   \n",
       "22  [Mistral AI\\nMistral AI SAS is a French artifi...   \n",
       "23  [Mistral AI\\nMistral AI SAS is a French artifi...   \n",
       "24  [es/tripling-down-on-mistral-ai). www.generalc...   \n",
       "25  [Mistral AI\\nMistral AI SAS is a French artifi...   \n",
       "26  [Hugging Face, Inc.\\nCompany type Private\\nInd...   \n",
       "27  [Hugging Face, Inc.\\nCompany type Private\\nInd...   \n",
       "28  [Hugging Face, Inc.\\nCompany type Private\\nInd...   \n",
       "29  [Hugging Face, Inc.\\nCompany type Private\\nInd...   \n",
       "30  [OpenAI's \"Blossom\" is\\nused as a symbol for\\n...   \n",
       "31  [In August 2023, the company announced that it...   \n",
       "32  [September 2020 failed to materialize followin...   \n",
       "33  [Nvidia Corporation\\nLogo used since 2006\\nHea...   \n",
       "34  [On May 12, 2022, Nvidia announced that they a...   \n",
       "35  [applications such as video editing, 3D render...   \n",
       "36  [10-year financials (2016‚Äì2025)\\nYear Revenue\\...   \n",
       "37  [DeepSeek is headquartered in Hangzhou, Zhejia...   \n",
       "38  [DeepSeek is headquartered in Hangzhou, Zhejia...   \n",
       "39  [The DeepSeek login page following a\\ncyberatt...   \n",
       "40  [DeepSeek's models are described as \"open weig...   \n",
       "41  [real-time problem-solving. DeepSeek claimed t...   \n",
       "\n",
       "                                             response  \\\n",
       "0             OpenAI was founded on December 8, 2015.   \n",
       "1   The founders of OpenAI are Sam Altman, Elon Mu...   \n",
       "2   OpenAI's mission is to develop \"safe and benef...   \n",
       "3   Some key products developed by OpenAI include ...   \n",
       "4   OpenAI is headquartered at 1455 3rd Street, Sa...   \n",
       "5                 OpenAI's current CEO is Sam Altman.   \n",
       "6           Microsoft invested $10 billion in OpenAI.   \n",
       "7   The estimated revenue of OpenAI in 2024 is $1 ...   \n",
       "8   Elon Musk left the board of an AI safety group...   \n",
       "9   The name of OpenAI‚Äôs AI chatbot released in No...   \n",
       "10  I don't have enough information to answer this...   \n",
       "11  Anthropic was founded by Dario Amodei, Daniela...   \n",
       "12  The name of Anthropic's language model is Claude.   \n",
       "13  The companies that invested billions in Anthro...   \n",
       "14  Anthropic is headquartered in San Francisco, C...   \n",
       "15  Anthropic's public-benefit structure is called...   \n",
       "16         DeepMind was founded on 23 September 2010.   \n",
       "17  DeepMind was founded by Demis Hassabis, Shane ...   \n",
       "18                  Google acquired DeepMind in 2014.   \n",
       "19  Some of DeepMind's notable products include Al...   \n",
       "20      DeepMind is headquartered in London, England.   \n",
       "21           Mistral AI was founded on 28 April 2023.   \n",
       "22  Mistral AI was founded by Arthur Mensch, Guill...   \n",
       "23  Mistral AI is known for specializing in open-w...   \n",
       "24  Mistral AI announced a partnership with Micros...   \n",
       "25              Mistral AI is based in Paris, France.   \n",
       "26                  Hugging Face was founded in 2016.   \n",
       "27  The founders of Hugging Face are Cl√©ment Delan...   \n",
       "28  Hugging Face is headquartered in Manhattan, Ne...   \n",
       "29  Hugging Face is most known for its transformer...   \n",
       "30  I don't have enough information to answer this...   \n",
       "31  In 2022, Hugging Face acquired Gradio, an open...   \n",
       "32  Nvidia was founded by Jensen Huang, Chris Mala...   \n",
       "33  Nvidia is headquartered in Santa Clara, Califo...   \n",
       "34  CUDA is Nvidia's software platform and API tha...   \n",
       "35  The Nvidia product aimed at the consumer marke...   \n",
       "36  Nvidia's fiscal year 2025 revenue is $130,497 ...   \n",
       "37           DeepSeek is based in Hangzhou, Zhejiang.   \n",
       "38          DeepSeek was co-founded by Liang Wenfeng.   \n",
       "39  DeepSeek launched the DeepSeek chatbot based o...   \n",
       "40  DeepSeek's model training is unique because it...   \n",
       "41  DeepSeek-R1 uses \"open weight\" licensing, mean...   \n",
       "\n",
       "                                            reference  nv_accuracy  \\\n",
       "0                                    December 8, 2015         1.00   \n",
       "1   John Schulman, Elon Musk, Ilya Sutskever, Sam ...         0.50   \n",
       "2        To ensure that AGI benefits all of humanity.         0.25   \n",
       "3            ChatGPT, GPT models, DALL¬∑E, Codex, Sora         0.50   \n",
       "4                           San Francisco, California         0.75   \n",
       "5                                          Sam Altman         1.00   \n",
       "6                                           Microsoft         0.25   \n",
       "7                                        $3.7 billion         0.00   \n",
       "8   Due to a potential future conflict of interest...         0.50   \n",
       "9                                             ChatGPT         1.00   \n",
       "10                                               2021         0.00   \n",
       "11  Dario Amodei, Daniela Amodei, Jared Kaplan, Ja...         1.00   \n",
       "12                                             Claude         1.00   \n",
       "13                                  Amazon and Google         0.75   \n",
       "14                          San Francisco, California         1.00   \n",
       "15                Delaware public-benefit corporation         1.00   \n",
       "16                                 September 23, 2010         1.00   \n",
       "17       Demis Hassabis, Shane Legg, Mustafa Suleyman         1.00   \n",
       "18                                             Google         1.00   \n",
       "19           AlphaGo, AlphaStar, AlphaFold, AlphaZero         0.50   \n",
       "20                                    London, England         1.00   \n",
       "21                                         April 2023         0.75   \n",
       "22  Arthur Mensch, Guillaume Lample, Timoth√©e Lacroix         1.00   \n",
       "23                  Open-weight large language models         1.00   \n",
       "24                         Partnership with Microsoft         1.00   \n",
       "25                                      Paris, France         1.00   \n",
       "26                                               2016         1.00   \n",
       "27     Cl√©ment Delangue, Julien Chaumond, Thomas Wolf         1.00   \n",
       "28                                      New York City         1.00   \n",
       "29                       Transformers library for NLP         0.75   \n",
       "30  A multilingual large language model with 176 b...         0.00   \n",
       "31                                             Gradio         1.00   \n",
       "32      Jensen Huang, Chris Malachowsky, Curtis Priem         1.00   \n",
       "33                            Santa Clara, California         1.00   \n",
       "34  A platform and API for parallel computing usin...         0.50   \n",
       "35                                            GeForce         0.00   \n",
       "36                                    $130.57 billion         0.75   \n",
       "37                          Hangzhou, Zhejiang, China         0.75   \n",
       "38                                      Liang Wenfeng         1.00   \n",
       "39                                        DeepSeek-R1         0.75   \n",
       "40           Low cost and efficiency using MoE layers         0.50   \n",
       "41                                        MIT License         0.00   \n",
       "\n",
       "    nv_context_relevance  nv_response_groundedness  \n",
       "0                    1.0                       1.0  \n",
       "1                    1.0                       1.0  \n",
       "2                    1.0                       1.0  \n",
       "3                    1.0                       1.0  \n",
       "4                    1.0                       1.0  \n",
       "5                    1.0                       1.0  \n",
       "6                    0.5                       1.0  \n",
       "7                    1.0                       1.0  \n",
       "8                    0.5                       1.0  \n",
       "9                    1.0                       1.0  \n",
       "10                   0.0                       0.0  \n",
       "11                   1.0                       1.0  \n",
       "12                   1.0                       1.0  \n",
       "13                   1.0                       1.0  \n",
       "14                   1.0                       1.0  \n",
       "15                   1.0                       1.0  \n",
       "16                   1.0                       1.0  \n",
       "17                   1.0                       1.0  \n",
       "18                   1.0                       1.0  \n",
       "19                   1.0                       1.0  \n",
       "20                   1.0                       1.0  \n",
       "21                   1.0                       1.0  \n",
       "22                   1.0                       1.0  \n",
       "23                   1.0                       1.0  \n",
       "24                   1.0                       1.0  \n",
       "25                   1.0                       1.0  \n",
       "26                   1.0                       1.0  \n",
       "27                   1.0                       1.0  \n",
       "28                   1.0                       1.0  \n",
       "29                   1.0                       1.0  \n",
       "30                   0.5                       0.0  \n",
       "31                   1.0                       1.0  \n",
       "32                   1.0                       1.0  \n",
       "33                   1.0                       1.0  \n",
       "34                   1.0                       1.0  \n",
       "35                   1.0                       1.0  \n",
       "36                   1.0                       1.0  \n",
       "37                   1.0                       1.0  \n",
       "38                   1.0                       1.0  \n",
       "39                   1.0                       1.0  \n",
       "40                   1.0                       1.0  \n",
       "41                   0.5                       1.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAGAS Evaluation with Visualizations\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "metrics = [\n",
    "    AnswerAccuracy(),   # Measures correctness against reference answer\n",
    "    ContextRelevance(), # Measures relevance of retrieved context\n",
    "    ResponseGroundedness() # Measures if response is grounded in context\n",
    "]\n",
    "\n",
    "print(\"Running RAGAS evaluation...\")\n",
    "# Wrap LLM for RAGAS\n",
    "ragas_llm = LangchainLLMWrapper(llm)\n",
    "# Run evaluation\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=metrics,\n",
    "    llm=ragas_llm\n",
    ")\n",
    "print(\"‚úì Evaluation complete\")\n",
    "print(result)\n",
    "result.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
